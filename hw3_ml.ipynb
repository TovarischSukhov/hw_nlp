{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'anna.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-aac41f107d06>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m#data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'anna.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0manna\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'sonets.txt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'anna.txt'"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import re\n",
    "import numpy as np\n",
    "from statistics import median\n",
    "\n",
    "\n",
    "#data\n",
    "with open('anna.txt', encoding='utf-8') as f:\n",
    "    anna = f.read()\n",
    "with open('sonets.txt', encoding='utf-8') as f:\n",
    "    sonet = f.read()\n",
    "\n",
    "anna_sentences = re.split(r'(?:[.]\\s*){3}|[.?!]', anna)\n",
    "sonet_sentences = re.split(r'(?:[.]\\s*){3}|[.?!]', sonet)       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "punct = re.compile(',|-|:')\n",
    "vowel = re.compile('у|е|ы|а|о|я|и|ю|э')\n",
    "letter = re.compile('\\w')\n",
    "\n",
    "def count_feach(var, sent_list):\n",
    "    out_stats = []\n",
    "    \n",
    "    for sent in sent_list:\n",
    "        sent = punct.sub('', sent).lower()\n",
    "        \n",
    "        len_count = len(letter.findall(sent))  #длина предложения в буквах\n",
    "        count_letter = len(set(letter.findall(sent)))  #число различных букв в предложении\n",
    "        count_vowels = len(vowel.findall(sent))  #число гласных в предложении\n",
    "        med_letters = 0  #медиана числа букв в слове\n",
    "        med_vowels = 0  #медиана числа гласных в слове\n",
    "        \n",
    "        sent_vowels = []\n",
    "        sent_letters = []\n",
    "        for word in sent.split(' '):\n",
    "            sent_letters.append(len(letter.findall(sent)))\n",
    "            sent_vowels.append(len(vowel.findall(sent)))\n",
    "            \n",
    "        med_letters = median(sorted(sent_letters))\n",
    "        med_vowels = median(sorted(sent_vowels))\n",
    "        \n",
    "        out_stats.append([len_count, count_letter, count_vowels, med_letters, med_vowels, var])\n",
    "    return out_stats\n",
    "        \n",
    "anna_feach = count_feach(1, anna_sentences)\n",
    "sonet_feach = count_feach(2, sonet_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "    \n",
    "def plot_try(i,j,anna=anna_sentences, sonet=sonet_sentences):\n",
    "    \n",
    "    anna = np.array(anna)\n",
    "    sonet = np.array(sonet)\n",
    "    plt.figure()\n",
    "    plt.plot(anna[i,:], anna[j,:], 'o')\n",
    "    plt.show()\n",
    "    \n",
    "    #plt.plot(data[:][i], data[:][j], 'ro')\n",
    "    #plt.show()\n",
    "\n",
    "anna = np.array(anna_feach)\n",
    "sonet = np.array(sonet_feach)\n",
    "#print(anna)   \n",
    "plt.figure()\n",
    "plt.plot(anna[:,0], anna[:,1], 'o')\n",
    "plt.plot(sonet[:,0], sonet[:,1], 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(anna[:,1], anna[:,2], 'o')\n",
    "plt.plot(sonet[:,1], sonet[:,2], 'x')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from math import ceil\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "cols = ['length', 'letter_count', 'vowels', 'med_letters', 'med_vowels', 'var']\n",
    "ana = pd.DataFrame.from_records(anna_feach, columns=cols)\n",
    "snt = pd.DataFrame.from_records(sonet_feach, columns=cols)\n",
    "\n",
    "train = ana[0:int(ceil(len(ana)*0.7))]\n",
    "train = train.append(snt[0:int(ceil(len(snt)*0.7))])\n",
    "\n",
    "train.reset_index(level=0, inplace=True)#(range(0,len(train)))\n",
    "\n",
    "test = ana[int(ceil(len(ana)*0.7)):len(ana)]\n",
    "test = test.append(snt[int(ceil(len(snt)*0.7)):len(snt)])\n",
    "test.reset_index(level=0, inplace=True)\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "#print(train[0:])\n",
    "col = ['length', 'letter_count', 'vowels', 'med_letters', 'med_vowels']\n",
    "rf.fit(train[col], train['var'])\n",
    "\n",
    "print(classification_report(rf.predict(test[col]), test['var']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно, что из-за несбаллансированности выборки, точность определения сонетов маленькая, в следующем примере, я делаю более сбаллансированную выборку - беру одинаковое количество предложений для разных типов текста. \n",
    "Общие значения получаются хуже, однако более равномерно предсказываются оба класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train = ana[0:int(ceil(len(snt)*0.7))]# + snt[0:int(ceil(len(ana)*0.7))]\n",
    "train = train.append(snt[0:int(ceil(len(snt)*0.7))])\n",
    "train.reset_index(level=0, inplace=True)\n",
    "#print(train.head())\n",
    "test = ana[int(ceil(len(snt)*0.7)):len(snt)]\n",
    "test = test.append(snt[int(ceil(len(snt)*0.7)):len(snt)])\n",
    "test.reset_index(level=0, inplace=True)\n",
    "#print(test.head())\n",
    "#print(test.head())\n",
    "\n",
    "rf = RandomForestClassifier()\n",
    "#print(train[0:])\n",
    "col = ['length', 'letter_count', 'vowels', 'med_letters', 'med_vowels']\n",
    "rf.fit(train[col], train['var'])\n",
    "\n",
    "print(classification_report(rf.predict(test[col]), test['var']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "c = 0\n",
    "#print(test.head())\n",
    "#print(len(test))\n",
    "#print(test.loc[])\n",
    "\n",
    "for i in range(1,len(test)):\n",
    "    #while c <= 3:\n",
    "    fp = test.loc[i]\n",
    "    #print(type(fp))\n",
    "    if rf.predict(fp.loc[col]) != fp['var']:\n",
    "        print('new mistake')\n",
    "        print(anna_sentences[int(i+len(snt)*0.7)])\n",
    "        print(fp.loc[col][i], fp['var'][i])\n",
    "        print()\n",
    "        c += 1\n",
    "        if c == 3:\n",
    "            break\n",
    "#Предположение - классификатор ошибается на коротких предложениях"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
